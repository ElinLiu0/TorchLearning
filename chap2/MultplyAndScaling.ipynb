{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个3x4和4x3的张量\n",
    "a = torch.randn(3, 4)\n",
    "b = torch.randn(4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.8833, -2.6036, -0.1301],\n",
       "        [ 0.1878,  1.2772, -0.5514],\n",
       "        [ 1.1155, -3.1864, -5.7196]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用torch.mm()函数进行矩阵乘法\n",
    "c = torch.mm(a, b)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.8833, -2.6036, -0.1301],\n",
       "        [ 0.1878,  1.2772, -0.5514],\n",
       "        [ 1.1155, -3.1864, -5.7196]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 同样支持内部方法进行矩阵乘法\n",
    "a.mm(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.8833, -2.6036, -0.1301],\n",
       "        [ 0.1878,  1.2772, -0.5514],\n",
       "        [ 1.1155, -3.1864, -5.7196]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用@符号进行矩阵乘法，参见Python3.5的PEP465标准\n",
    "a @ b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Python3.5 PEP465标准简介](https://peps.python.org/pep-0465/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用bmm()函数执行三维矩阵内积\n",
    "a = torch.randn(2,3,4)\n",
    "b = torch.randn(2,4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.4967,  3.1340,  0.2798],\n",
       "         [-1.2403,  0.7567,  1.8853],\n",
       "         [-1.0319, -0.0904,  0.1666]],\n",
       "\n",
       "        [[ 1.8387,  0.7310,  0.0743],\n",
       "         [-0.7997, -0.6287,  0.3579],\n",
       "         [ 0.7572,  1.5453, -2.3106]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bmm(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.4967,  3.1340,  0.2798],\n",
       "         [-1.2403,  0.7567,  1.8853],\n",
       "         [-1.0319, -0.0904,  0.1666]],\n",
       "\n",
       "        [[ 1.8387,  0.7310,  0.0743],\n",
       "         [-0.7997, -0.6287,  0.3579],\n",
       "         [ 0.7572,  1.5453, -2.3106]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 调用.einsum()函数执行与bmm()函数相同的操作，其中第一个参数代表爱因斯坦并缩公式将以什么什么样的顺序对张量进行乘法\n",
    "torch.einsum('bik,bkj->bij', a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机生成四个张量\n",
    "t1 = torch.randn(3,4)\n",
    "t2 = torch.randn(3,4)\n",
    "t3 = torch.randn(3,4)\n",
    "t4 = torch.randn(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4662, -0.4544,  0.3980],\n",
       "         [ 0.3013, -0.4269, -0.7567],\n",
       "         [-1.4668,  0.3714, -1.3688],\n",
       "         [-0.9313,  1.8039,  0.6439]],\n",
       "\n",
       "        [[ 0.0982, -0.7600,  1.7216],\n",
       "         [ 0.1848, -0.0270,  0.7021],\n",
       "         [-0.6173,  1.0759, -1.5607],\n",
       "         [-0.4211,  0.2061,  0.5086]],\n",
       "\n",
       "        [[-0.5107,  0.3416, -0.3116],\n",
       "         [-1.1838,  1.5768,  1.1412],\n",
       "         [-0.4783,  1.5372,  0.4975],\n",
       "         [-0.6660, -1.4903, -0.7324]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 沿着最后一个维度做堆叠，返回大小为3x4x3的张量\n",
    "# 使用stack()函数沿着最后一个维度进行堆叠\n",
    "torch.stack([t1,t2,t3],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 14])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 沿着最后一个维度进做拼接，返回大小为3x14的张量\n",
    "# 使用cat()函数沿着最后一个维度进行拼接\n",
    "torch.cat([t1,t2,t3,t4],-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4662,  0.3013, -1.4668, -0.9313, -0.4544, -0.4269,  0.3714,  1.8039,\n",
       "          0.3980, -0.7567, -1.3688,  0.6439,  1.6823, -0.7890],\n",
       "        [ 0.0982,  0.1848, -0.6173, -0.4211, -0.7600, -0.0270,  1.0759,  0.2061,\n",
       "          1.7216,  0.7021, -1.5607,  0.5086, -0.6334, -0.2726],\n",
       "        [-0.5107, -1.1838, -0.4783, -0.6660,  0.3416,  1.5768,  1.5372, -1.4903,\n",
       "         -0.3116,  1.1412,  0.4975, -0.7324, -0.1619, -0.3377]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([t1,t2,t3,t4],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5163,  0.1487,  0.9087,  1.4235, -0.4875,  0.8153],\n",
       "        [ 0.9250,  0.3164,  1.6501,  0.3666,  0.6521,  2.3090],\n",
       "        [-0.1082,  0.3181,  1.4343,  1.3567, -0.0178, -0.3439]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建一个3x6的张量\n",
    "t = torch.randn(3,6)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.5163],\n",
       "         [ 0.9250],\n",
       "         [-0.1082]]),\n",
       " tensor([[0.1487, 0.9087],\n",
       "         [0.3164, 1.6501],\n",
       "         [0.3181, 1.4343]]),\n",
       " tensor([[ 1.4235, -0.4875,  0.8153],\n",
       "         [ 0.3666,  0.6521,  2.3090],\n",
       "         [ 1.3567, -0.0178, -0.3439]]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 此时使用t.split()函数，并传入第一个参数为[1,2,3]\n",
    "# 所以此时将会返回三个矩阵，第一个矩阵大小为3x1，第二个矩阵大小为3x2，第三个矩阵大小为3x3\n",
    "t.split([1,2,3],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.5163,  0.1487,  0.9087],\n",
       "         [ 0.9250,  0.3164,  1.6501],\n",
       "         [-0.1082,  0.3181,  1.4343]]),\n",
       " tensor([[ 1.4235, -0.4875,  0.8153],\n",
       "         [ 0.3666,  0.6521,  2.3090],\n",
       "         [ 1.3567, -0.0178, -0.3439]]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 此时如果spilt()函数的第一个参数为3，那么将会返回三个矩阵，每个矩阵大小为3x3\n",
    "# 此时split()函数的分割逻辑为：3x3x2\n",
    "t.split(3,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.5163,  0.1487],\n",
       "         [ 0.9250,  0.3164],\n",
       "         [-0.1082,  0.3181]]),\n",
       " tensor([[0.9087, 1.4235],\n",
       "         [1.6501, 0.3666],\n",
       "         [1.4343, 1.3567]]),\n",
       " tensor([[-0.4875,  0.8153],\n",
       "         [ 0.6521,  2.3090],\n",
       "         [-0.0178, -0.3439]]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 把张量沿着最后一个维度分割为三个张量，大小为3x2\n",
    "# 此时t.chunk()的生成逻辑为：3x2x3\n",
    "t.chunk(3,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建一个3x4的张量\n",
    "t = torch.randn(3,4)\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用unsqueeze()函数扩增最后一个维度\n",
    "t.unsqueeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 4, 1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 随机生成一个张量，有两个维度大小为1\n",
    "t = torch.rand(1,3,4,1)\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.2678],\n",
       "          [0.8881],\n",
       "          [0.6137],\n",
       "          [0.9543]],\n",
       "\n",
       "         [[0.2122],\n",
       "          [0.2076],\n",
       "          [0.5531],\n",
       "          [0.9949]],\n",
       "\n",
       "         [[0.2597],\n",
       "          [0.7400],\n",
       "          [0.4926],\n",
       "          [0.0481]]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用squeeze()函数压缩所有大小为1的维度\n",
    "t.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2678, 0.8881, 0.6137, 0.9543],\n",
       "        [0.2122, 0.2076, 0.5531, 0.9949],\n",
       "        [0.2597, 0.7400, 0.4926, 0.0481]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = t.squeeze()\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个3x4x5的张量和3x5的张量2\n",
    "t1 = torch.randn(3,4,5)\n",
    "t2 = torch.randn(3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2176,  0.4615, -1.0016, -0.6195, -0.5222],\n",
       "         [ 0.1253, -0.2093,  0.1138,  0.7298,  0.0337],\n",
       "         [ 0.9683,  0.1076, -0.6202,  0.7227,  0.9124],\n",
       "         [-0.2749, -1.2052, -0.4937, -1.0912,  1.0093]],\n",
       "\n",
       "        [[ 2.0557,  1.4009,  0.1253, -0.1054,  0.7219],\n",
       "         [-0.3578,  0.0100, -0.2207,  0.5503, -0.1329],\n",
       "         [ 0.9601,  1.1066,  0.8950, -1.6786, -0.9660],\n",
       "         [ 0.0076, -1.2044,  2.3931, -1.7390,  1.7042]],\n",
       "\n",
       "        [[ 0.0369, -1.0937,  1.8097, -1.4773, -0.4028],\n",
       "         [-1.4418,  0.7915, -0.0498,  0.3743,  0.6611],\n",
       "         [-0.2572,  0.7175,  0.5088,  0.9765, -0.4874],\n",
       "         [ 1.0797,  0.4570,  3.2796,  0.2798, -0.7565]]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6632, -1.4441,  0.7634,  1.1896,  0.0950],\n",
       "        [ 2.1381, -0.9901, -0.7626, -1.1137, -0.7779],\n",
       "        [-0.4345, -0.1404, -0.8118,  0.6688,  1.5414]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用unsqueeze()函数扩增t2的维度，使其编程3x1x5\n",
    "t2 = t2.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 4, 5]), torch.Size([3, 1, 5]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 检查大小\n",
    "t1.shape, t2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8808, -0.9826, -0.2382,  0.5701, -0.4273],\n",
       "         [ 0.7885, -1.6534,  0.8772,  1.9194,  0.1286],\n",
       "         [ 1.6316, -1.3365,  0.1432,  1.9123,  1.0074],\n",
       "         [ 0.3884, -2.6493,  0.2697,  0.0984,  1.1043]],\n",
       "\n",
       "        [[ 4.1938,  0.4108, -0.6373, -1.2191, -0.0560],\n",
       "         [ 1.7803, -0.9801, -0.9833, -0.5633, -0.9109],\n",
       "         [ 3.0982,  0.1165,  0.1324, -2.7923, -1.7439],\n",
       "         [ 2.1457, -2.1945,  1.6304, -2.8527,  0.9262]],\n",
       "\n",
       "        [[-0.3976, -1.2341,  0.9979, -0.8086,  1.1386],\n",
       "         [-1.8764,  0.6511, -0.8616,  1.0430,  2.2025],\n",
       "         [-0.6917,  0.5770, -0.3029,  1.6453,  1.0540],\n",
       "         [ 0.6452,  0.3166,  2.4678,  0.9486,  0.7850]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 广播求和，最后结果为3x4x5的张量\n",
    "t3 = t1 + t2\n",
    "t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 5])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "42338d186148b0cdac95e402a6383b43087380f7dd608a48bf55a16de9d059a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
